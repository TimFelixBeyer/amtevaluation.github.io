<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>MUSTER</title>

    <style>
      ul.pub {line-height: 20px;}
      ul.pub li {margin-bottom: 10px;}
      ol.multi-column {float: left; width: 100%; line-height: 10px;}
      ol.multi-column li {float: left; width: 50%; margin-bottom: 10px;}
    </style>


  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer" style="height: 100px;">
        <header class="inner">
          <h1>MUSTER: Music score transcription evaluation metrics</h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

<strong>MUSTER</strong> is a set of evaluation metrics for automatic music score transcription systems. Given a correct musical score and an estimated musical score, both in the <strong>MusicXML</strong> format, the metrics calculate how similar they are.

        <div style="height:20px;"></div>

        <h3>Download</h3>

        <div style="height:20px;"></div>

        <div style="margin:auto;padding:10px;text-align:center;border: 1px solid rgb(0,140,235); width:500px;background-color:rgba(0,140,235,0.1);">
          <a href="https://amtevaluation.github.io/MUSTER_v220118.zip"><strong><font color="#ff0080">Download the evaluation script</font></strong></a><br>
        </div>

        <div style="height:20px;"></div>

        <h3>About the MUSTER metrics</h3>

        The <strong>MUsic Score Transcription Error Rate (MUSTER)</strong> metrics are edit-distance-based metrics, similar to the word error rate (WER) used for evaluating automatic speech recognition systems. Each of the six metrics evaluates a specific aspect of musical score. These metrics are error rates; a lower value means a larger similarity between the esimated score and the ground truth.

        <div style="height:20px;"></div>

        <h3>Updates</h3>
        You can download the old versions from <a href="https://github.com/amtevaluation/amtevaluation.github.io">the Github repository</a>.<br><br>

        (2022/Jan/18) Added an output file with details of error analysis. Some internal modules were modified.<br>
        (2021/Dec/17) Fixed somes bugs.<br>

        <div style="height:20px;"></div>

        <h3>References</h3>

        The edit-distance-based metrics are first introduced in Ref. [1]. The metrics for voices are defined in Ref. [2].<br>
        <br>

        [1] Eita Nakamura, Emmanouil Benetos, Kazuyoshi Yoshii, Simon Dixon, “Towards Complete Polyphonic Music Transcription: Integrating Multi-Pitch Detection and Rhythm Quantization,” Proc. 43rd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 101-105, 2018.<br>

        [2] Yuki Hiramatsu, Eita Nakamura, Kazuyoshi Yoshii, “Joint Estimation of Note Values and Voices for Audio-to-Score Piano Transcription,” Proc. 22nd International Society for Music Information Retrieval Conference (ISMIR), 2021.

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Maintained by <a href="https://eita-nakamura.github.io/index.html"><font color="#000000">Eita Nakamura</font></a>　　　(Last updated:Jan 2022)</p>
      </footer>
    </div>

  </body>
</html>
